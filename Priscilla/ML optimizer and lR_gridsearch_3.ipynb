{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b37d8af",
   "metadata": {},
   "source": [
    "## Grid search code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07b40442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['apple', 'banana', 'mixed', 'orange']\n",
      "Using device: cpu\n",
      "\n",
      "=== Training with SGD, lr=0.01, lr_decay=0.9 ===\n",
      "Epoch 1, Train Acc: 0.2643, Val Acc: 0.3708\n",
      "Epoch 2, Train Acc: 0.4143, Val Acc: 0.4458\n",
      "Epoch 3, Train Acc: 0.4750, Val Acc: 0.5583\n",
      "Epoch 4, Train Acc: 0.6268, Val Acc: 0.6708\n",
      "Epoch 5, Train Acc: 0.6196, Val Acc: 0.6542\n",
      "Epoch 6, Train Acc: 0.7179, Val Acc: 0.7875\n",
      "Epoch 7, Train Acc: 0.7625, Val Acc: 0.7458\n",
      "Epoch 8, Train Acc: 0.7821, Val Acc: 0.8208\n",
      "Epoch 9, Train Acc: 0.7839, Val Acc: 0.7625\n",
      "Epoch 10, Train Acc: 0.7839, Val Acc: 0.8167\n",
      "Epoch 11, Train Acc: 0.8321, Val Acc: 0.8083\n",
      "Epoch 12, Train Acc: 0.8036, Val Acc: 0.8042\n",
      "Epoch 13, Train Acc: 0.8357, Val Acc: 0.8375\n",
      "Epoch 14, Train Acc: 0.8661, Val Acc: 0.7875\n",
      "Epoch 15, Train Acc: 0.7768, Val Acc: 0.7542\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.94      0.79      0.86        19\n",
      "      banana       0.89      0.94      0.92        18\n",
      "       mixed       0.38      0.60      0.46         5\n",
      "      orange       0.94      0.89      0.91        18\n",
      "\n",
      "    accuracy                           0.85        60\n",
      "   macro avg       0.79      0.81      0.79        60\n",
      "weighted avg       0.88      0.85      0.86        60\n",
      "\n",
      "\n",
      "=== Training with SGD, lr=0.01, lr_decay=0.7 ===\n",
      "Epoch 1, Train Acc: 0.2875, Val Acc: 0.4000\n",
      "Epoch 2, Train Acc: 0.3679, Val Acc: 0.3875\n",
      "Epoch 3, Train Acc: 0.4839, Val Acc: 0.4792\n",
      "Epoch 4, Train Acc: 0.5679, Val Acc: 0.6917\n",
      "Epoch 5, Train Acc: 0.6321, Val Acc: 0.6083\n",
      "Epoch 6, Train Acc: 0.7000, Val Acc: 0.6750\n",
      "Epoch 7, Train Acc: 0.7232, Val Acc: 0.6750\n",
      "Epoch 8, Train Acc: 0.7786, Val Acc: 0.7542\n",
      "Epoch 9, Train Acc: 0.7750, Val Acc: 0.8417\n",
      "Epoch 10, Train Acc: 0.8232, Val Acc: 0.8000\n",
      "Epoch 11, Train Acc: 0.8393, Val Acc: 0.8208\n",
      "Epoch 12, Train Acc: 0.8375, Val Acc: 0.8458\n",
      "Epoch 13, Train Acc: 0.8625, Val Acc: 0.8167\n",
      "Epoch 14, Train Acc: 0.8179, Val Acc: 0.8250\n",
      "Epoch 15, Train Acc: 0.8750, Val Acc: 0.8250\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.94      0.89      0.92        19\n",
      "      banana       0.89      0.89      0.89        18\n",
      "       mixed       0.50      0.60      0.55         5\n",
      "      orange       0.89      0.89      0.89        18\n",
      "\n",
      "    accuracy                           0.87        60\n",
      "   macro avg       0.81      0.82      0.81        60\n",
      "weighted avg       0.87      0.87      0.87        60\n",
      "\n",
      "\n",
      "=== Training with SGD, lr=0.01, lr_decay=0.5 ===\n",
      "Epoch 1, Train Acc: 0.2964, Val Acc: 0.4042\n",
      "Epoch 2, Train Acc: 0.3786, Val Acc: 0.3917\n",
      "Epoch 3, Train Acc: 0.4750, Val Acc: 0.5833\n",
      "Epoch 4, Train Acc: 0.5857, Val Acc: 0.6000\n",
      "Epoch 5, Train Acc: 0.6839, Val Acc: 0.6708\n",
      "Epoch 6, Train Acc: 0.7125, Val Acc: 0.7750\n",
      "Epoch 7, Train Acc: 0.6804, Val Acc: 0.7458\n",
      "Epoch 8, Train Acc: 0.7857, Val Acc: 0.8000\n",
      "Epoch 9, Train Acc: 0.7911, Val Acc: 0.8458\n",
      "Epoch 10, Train Acc: 0.7821, Val Acc: 0.8250\n",
      "Epoch 11, Train Acc: 0.8375, Val Acc: 0.8167\n",
      "Epoch 12, Train Acc: 0.8179, Val Acc: 0.8333\n",
      "Epoch 13, Train Acc: 0.8446, Val Acc: 0.8458\n",
      "Epoch 14, Train Acc: 0.8464, Val Acc: 0.8250\n",
      "Epoch 15, Train Acc: 0.8643, Val Acc: 0.8292\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.94      0.89      0.92        19\n",
      "      banana       0.89      0.89      0.89        18\n",
      "       mixed       0.50      0.60      0.55         5\n",
      "      orange       0.89      0.89      0.89        18\n",
      "\n",
      "    accuracy                           0.87        60\n",
      "   macro avg       0.81      0.82      0.81        60\n",
      "weighted avg       0.87      0.87      0.87        60\n",
      "\n",
      "\n",
      "=== Training with SGD, lr=0.005, lr_decay=0.9 ===\n",
      "Epoch 1, Train Acc: 0.2571, Val Acc: 0.3375\n",
      "Epoch 2, Train Acc: 0.4179, Val Acc: 0.3458\n",
      "Epoch 3, Train Acc: 0.4839, Val Acc: 0.5083\n",
      "Epoch 4, Train Acc: 0.5536, Val Acc: 0.6333\n",
      "Epoch 5, Train Acc: 0.6375, Val Acc: 0.6750\n",
      "Epoch 6, Train Acc: 0.7071, Val Acc: 0.7417\n",
      "Epoch 7, Train Acc: 0.7429, Val Acc: 0.8125\n",
      "Epoch 8, Train Acc: 0.7625, Val Acc: 0.8333\n",
      "Epoch 9, Train Acc: 0.7643, Val Acc: 0.8208\n",
      "Epoch 10, Train Acc: 0.8107, Val Acc: 0.8583\n",
      "Epoch 11, Train Acc: 0.8018, Val Acc: 0.8625\n",
      "Epoch 12, Train Acc: 0.8268, Val Acc: 0.8667\n",
      "Epoch 13, Train Acc: 0.8357, Val Acc: 0.8458\n",
      "Epoch 14, Train Acc: 0.8536, Val Acc: 0.8333\n",
      "Epoch 15, Train Acc: 0.8696, Val Acc: 0.8333\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.94      0.89      0.92        19\n",
      "      banana       0.94      0.89      0.91        18\n",
      "       mixed       0.57      0.80      0.67         5\n",
      "      orange       0.89      0.89      0.89        18\n",
      "\n",
      "    accuracy                           0.88        60\n",
      "   macro avg       0.84      0.87      0.85        60\n",
      "weighted avg       0.90      0.88      0.89        60\n",
      "\n",
      "\n",
      "=== Training with SGD, lr=0.005, lr_decay=0.7 ===\n",
      "Epoch 1, Train Acc: 0.3036, Val Acc: 0.3125\n",
      "Epoch 2, Train Acc: 0.3607, Val Acc: 0.4167\n",
      "Epoch 3, Train Acc: 0.4161, Val Acc: 0.3708\n",
      "Epoch 4, Train Acc: 0.4696, Val Acc: 0.4583\n",
      "Epoch 5, Train Acc: 0.4964, Val Acc: 0.6333\n",
      "Epoch 6, Train Acc: 0.6268, Val Acc: 0.6208\n",
      "Epoch 7, Train Acc: 0.6750, Val Acc: 0.7625\n",
      "Epoch 8, Train Acc: 0.7232, Val Acc: 0.7417\n",
      "Epoch 9, Train Acc: 0.7304, Val Acc: 0.6292\n",
      "Epoch 10, Train Acc: 0.7643, Val Acc: 0.8083\n",
      "Epoch 11, Train Acc: 0.7893, Val Acc: 0.8042\n",
      "Epoch 12, Train Acc: 0.7911, Val Acc: 0.7958\n",
      "Epoch 13, Train Acc: 0.8161, Val Acc: 0.8208\n",
      "Epoch 14, Train Acc: 0.8196, Val Acc: 0.8292\n",
      "Epoch 15, Train Acc: 0.8268, Val Acc: 0.8333\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.94      0.89      0.92        19\n",
      "      banana       0.89      0.89      0.89        18\n",
      "       mixed       0.50      0.60      0.55         5\n",
      "      orange       0.89      0.89      0.89        18\n",
      "\n",
      "    accuracy                           0.87        60\n",
      "   macro avg       0.81      0.82      0.81        60\n",
      "weighted avg       0.87      0.87      0.87        60\n",
      "\n",
      "\n",
      "=== Training with SGD, lr=0.005, lr_decay=0.5 ===\n",
      "Epoch 1, Train Acc: 0.2982, Val Acc: 0.3708\n",
      "Epoch 2, Train Acc: 0.3857, Val Acc: 0.3958\n",
      "Epoch 3, Train Acc: 0.4429, Val Acc: 0.5292\n",
      "Epoch 4, Train Acc: 0.5321, Val Acc: 0.5583\n",
      "Epoch 5, Train Acc: 0.5661, Val Acc: 0.5792\n",
      "Epoch 6, Train Acc: 0.6696, Val Acc: 0.6333\n",
      "Epoch 7, Train Acc: 0.6607, Val Acc: 0.7125\n",
      "Epoch 8, Train Acc: 0.7125, Val Acc: 0.7458\n",
      "Epoch 9, Train Acc: 0.7411, Val Acc: 0.7250\n",
      "Epoch 10, Train Acc: 0.7625, Val Acc: 0.7708\n",
      "Epoch 11, Train Acc: 0.7964, Val Acc: 0.8083\n",
      "Epoch 12, Train Acc: 0.7821, Val Acc: 0.8042\n",
      "Epoch 13, Train Acc: 0.8179, Val Acc: 0.8083\n",
      "Epoch 14, Train Acc: 0.8125, Val Acc: 0.8000\n",
      "Epoch 15, Train Acc: 0.8179, Val Acc: 0.8000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.89      0.89      0.89        19\n",
      "      banana       0.93      0.78      0.85        18\n",
      "       mixed       0.44      0.80      0.57         5\n",
      "      orange       0.94      0.89      0.91        18\n",
      "\n",
      "    accuracy                           0.85        60\n",
      "   macro avg       0.80      0.84      0.81        60\n",
      "weighted avg       0.88      0.85      0.86        60\n",
      "\n",
      "\n",
      "=== Training with Adam, lr=0.001, lr_decay=0.9 ===\n",
      "Epoch 1, Train Acc: 0.3786, Val Acc: 0.5250\n",
      "Epoch 2, Train Acc: 0.6179, Val Acc: 0.6500\n",
      "Epoch 3, Train Acc: 0.7482, Val Acc: 0.7250\n",
      "Epoch 4, Train Acc: 0.8018, Val Acc: 0.8417\n",
      "Epoch 5, Train Acc: 0.7964, Val Acc: 0.8375\n",
      "Epoch 6, Train Acc: 0.8232, Val Acc: 0.8333\n",
      "Epoch 7, Train Acc: 0.8339, Val Acc: 0.8292\n",
      "Epoch 8, Train Acc: 0.8571, Val Acc: 0.8208\n",
      "Epoch 9, Train Acc: 0.8696, Val Acc: 0.8500\n",
      "Epoch 10, Train Acc: 0.8911, Val Acc: 0.8500\n",
      "Epoch 11, Train Acc: 0.8893, Val Acc: 0.8583\n",
      "Epoch 12, Train Acc: 0.9054, Val Acc: 0.8625\n",
      "Epoch 13, Train Acc: 0.9018, Val Acc: 0.8833\n",
      "Epoch 14, Train Acc: 0.9107, Val Acc: 0.8708\n",
      "Epoch 15, Train Acc: 0.9268, Val Acc: 0.8833\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.89      0.89      0.89        19\n",
      "      banana       0.94      0.89      0.91        18\n",
      "       mixed       0.50      0.60      0.55         5\n",
      "      orange       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.88        60\n",
      "   macro avg       0.82      0.83      0.82        60\n",
      "weighted avg       0.89      0.88      0.89        60\n",
      "\n",
      "\n",
      "=== Training with Adam, lr=0.001, lr_decay=0.7 ===\n",
      "Epoch 1, Train Acc: 0.3768, Val Acc: 0.4792\n",
      "Epoch 2, Train Acc: 0.6696, Val Acc: 0.7875\n",
      "Epoch 3, Train Acc: 0.7554, Val Acc: 0.7917\n",
      "Epoch 4, Train Acc: 0.8071, Val Acc: 0.8250\n",
      "Epoch 5, Train Acc: 0.8196, Val Acc: 0.8083\n",
      "Epoch 6, Train Acc: 0.8464, Val Acc: 0.8458\n",
      "Epoch 7, Train Acc: 0.8679, Val Acc: 0.8417\n",
      "Epoch 8, Train Acc: 0.8571, Val Acc: 0.8042\n",
      "Epoch 9, Train Acc: 0.8982, Val Acc: 0.8292\n",
      "Epoch 10, Train Acc: 0.8839, Val Acc: 0.8458\n",
      "Epoch 11, Train Acc: 0.8857, Val Acc: 0.8625\n",
      "Epoch 12, Train Acc: 0.9143, Val Acc: 0.8417\n",
      "Epoch 13, Train Acc: 0.9107, Val Acc: 0.8542\n",
      "Epoch 14, Train Acc: 0.9429, Val Acc: 0.8500\n",
      "Epoch 15, Train Acc: 0.9304, Val Acc: 0.8500\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.94      0.89      0.92        19\n",
      "      banana       0.94      0.83      0.88        18\n",
      "       mixed       0.57      0.80      0.67         5\n",
      "      orange       0.89      0.94      0.92        18\n",
      "\n",
      "    accuracy                           0.88        60\n",
      "   macro avg       0.84      0.87      0.85        60\n",
      "weighted avg       0.90      0.88      0.89        60\n",
      "\n",
      "\n",
      "=== Training with Adam, lr=0.001, lr_decay=0.5 ===\n",
      "Epoch 1, Train Acc: 0.4857, Val Acc: 0.6250\n",
      "Epoch 2, Train Acc: 0.6964, Val Acc: 0.6833\n",
      "Epoch 3, Train Acc: 0.7357, Val Acc: 0.7792\n",
      "Epoch 4, Train Acc: 0.8125, Val Acc: 0.8333\n",
      "Epoch 5, Train Acc: 0.8107, Val Acc: 0.8083\n",
      "Epoch 6, Train Acc: 0.8464, Val Acc: 0.8542\n",
      "Epoch 7, Train Acc: 0.8929, Val Acc: 0.8500\n",
      "Epoch 8, Train Acc: 0.8839, Val Acc: 0.8625\n",
      "Epoch 9, Train Acc: 0.8929, Val Acc: 0.8583\n",
      "Epoch 10, Train Acc: 0.8911, Val Acc: 0.8375\n",
      "Epoch 11, Train Acc: 0.9125, Val Acc: 0.8500\n",
      "Epoch 12, Train Acc: 0.9268, Val Acc: 0.8458\n",
      "Epoch 13, Train Acc: 0.9375, Val Acc: 0.8500\n",
      "Epoch 14, Train Acc: 0.9286, Val Acc: 0.8500\n",
      "Epoch 15, Train Acc: 0.9214, Val Acc: 0.8625\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.89      0.89      0.89        19\n",
      "      banana       0.94      0.83      0.88        18\n",
      "       mixed       0.50      0.60      0.55         5\n",
      "      orange       0.84      0.89      0.86        18\n",
      "\n",
      "    accuracy                           0.85        60\n",
      "   macro avg       0.79      0.80      0.80        60\n",
      "weighted avg       0.86      0.85      0.85        60\n",
      "\n",
      "\n",
      "=== Training with Adam, lr=0.0005, lr_decay=0.9 ===\n",
      "Epoch 1, Train Acc: 0.3929, Val Acc: 0.4000\n",
      "Epoch 2, Train Acc: 0.5893, Val Acc: 0.6542\n",
      "Epoch 3, Train Acc: 0.7464, Val Acc: 0.7792\n",
      "Epoch 4, Train Acc: 0.7839, Val Acc: 0.7708\n",
      "Epoch 5, Train Acc: 0.8179, Val Acc: 0.8458\n",
      "Epoch 6, Train Acc: 0.8554, Val Acc: 0.7917\n",
      "Epoch 7, Train Acc: 0.8125, Val Acc: 0.8375\n",
      "Epoch 8, Train Acc: 0.8643, Val Acc: 0.8500\n",
      "Epoch 9, Train Acc: 0.8571, Val Acc: 0.8250\n",
      "Epoch 10, Train Acc: 0.8929, Val Acc: 0.8542\n",
      "Epoch 11, Train Acc: 0.8875, Val Acc: 0.8042\n",
      "Epoch 12, Train Acc: 0.8964, Val Acc: 0.8375\n",
      "Epoch 13, Train Acc: 0.9018, Val Acc: 0.8500\n",
      "Epoch 14, Train Acc: 0.9179, Val Acc: 0.8750\n",
      "Epoch 15, Train Acc: 0.9339, Val Acc: 0.8875\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.94      0.89      0.92        19\n",
      "      banana       0.94      0.94      0.94        18\n",
      "       mixed       0.67      0.80      0.73         5\n",
      "      orange       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.92        60\n",
      "   macro avg       0.88      0.90      0.88        60\n",
      "weighted avg       0.92      0.92      0.92        60\n",
      "\n",
      "\n",
      "=== Training with Adam, lr=0.0005, lr_decay=0.7 ===\n",
      "Epoch 1, Train Acc: 0.4821, Val Acc: 0.5958\n",
      "Epoch 2, Train Acc: 0.6732, Val Acc: 0.7042\n",
      "Epoch 3, Train Acc: 0.7375, Val Acc: 0.7875\n",
      "Epoch 4, Train Acc: 0.7982, Val Acc: 0.8083\n",
      "Epoch 5, Train Acc: 0.8304, Val Acc: 0.8167\n",
      "Epoch 6, Train Acc: 0.8429, Val Acc: 0.8375\n",
      "Epoch 7, Train Acc: 0.8643, Val Acc: 0.8167\n",
      "Epoch 8, Train Acc: 0.8946, Val Acc: 0.8375\n",
      "Epoch 9, Train Acc: 0.8875, Val Acc: 0.8375\n",
      "Epoch 10, Train Acc: 0.8679, Val Acc: 0.8083\n",
      "Epoch 11, Train Acc: 0.8929, Val Acc: 0.8250\n",
      "Epoch 12, Train Acc: 0.8964, Val Acc: 0.8292\n",
      "Epoch 13, Train Acc: 0.9250, Val Acc: 0.8542\n",
      "Epoch 14, Train Acc: 0.9214, Val Acc: 0.8625\n",
      "Epoch 15, Train Acc: 0.9196, Val Acc: 0.8500\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.89      0.89      0.89        19\n",
      "      banana       0.93      0.72      0.81        18\n",
      "       mixed       0.38      0.60      0.46         5\n",
      "      orange       0.89      0.94      0.92        18\n",
      "\n",
      "    accuracy                           0.83        60\n",
      "   macro avg       0.77      0.79      0.77        60\n",
      "weighted avg       0.86      0.83      0.84        60\n",
      "\n",
      "\n",
      "=== Training with Adam, lr=0.0005, lr_decay=0.5 ===\n",
      "Epoch 1, Train Acc: 0.4125, Val Acc: 0.4458\n",
      "Epoch 2, Train Acc: 0.6000, Val Acc: 0.6083\n",
      "Epoch 3, Train Acc: 0.7089, Val Acc: 0.7542\n",
      "Epoch 4, Train Acc: 0.7768, Val Acc: 0.7625\n",
      "Epoch 5, Train Acc: 0.8214, Val Acc: 0.8292\n",
      "Epoch 6, Train Acc: 0.8411, Val Acc: 0.8542\n",
      "Epoch 7, Train Acc: 0.8411, Val Acc: 0.8542\n",
      "Epoch 8, Train Acc: 0.8679, Val Acc: 0.8583\n",
      "Epoch 9, Train Acc: 0.8768, Val Acc: 0.8333\n",
      "Epoch 10, Train Acc: 0.8875, Val Acc: 0.8750\n",
      "Epoch 11, Train Acc: 0.8875, Val Acc: 0.8417\n",
      "Epoch 12, Train Acc: 0.8964, Val Acc: 0.8750\n",
      "Epoch 13, Train Acc: 0.9054, Val Acc: 0.8792\n",
      "Epoch 14, Train Acc: 0.8982, Val Acc: 0.8792\n",
      "Epoch 15, Train Acc: 0.9054, Val Acc: 0.8625\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.94      0.89      0.92        19\n",
      "      banana       0.94      0.94      0.94        18\n",
      "       mixed       0.62      1.00      0.77         5\n",
      "      orange       1.00      0.89      0.94        18\n",
      "\n",
      "    accuracy                           0.92        60\n",
      "   macro avg       0.88      0.93      0.89        60\n",
      "weighted avg       0.93      0.92      0.92        60\n",
      "\n",
      "\n",
      "=== Training with AdamW, lr=0.001, lr_decay=0.9 ===\n",
      "Epoch 1, Train Acc: 0.3893, Val Acc: 0.5333\n",
      "Epoch 2, Train Acc: 0.6232, Val Acc: 0.7542\n",
      "Epoch 3, Train Acc: 0.7393, Val Acc: 0.7708\n",
      "Epoch 4, Train Acc: 0.7714, Val Acc: 0.8333\n",
      "Epoch 5, Train Acc: 0.7982, Val Acc: 0.8333\n",
      "Epoch 6, Train Acc: 0.8429, Val Acc: 0.8250\n",
      "Epoch 7, Train Acc: 0.8643, Val Acc: 0.8250\n",
      "Epoch 8, Train Acc: 0.8625, Val Acc: 0.8667\n",
      "Epoch 9, Train Acc: 0.8786, Val Acc: 0.8458\n",
      "Epoch 10, Train Acc: 0.9000, Val Acc: 0.8500\n",
      "Epoch 11, Train Acc: 0.8893, Val Acc: 0.8333\n",
      "Epoch 12, Train Acc: 0.8929, Val Acc: 0.8458\n",
      "Epoch 13, Train Acc: 0.9089, Val Acc: 0.8500\n",
      "Epoch 14, Train Acc: 0.9143, Val Acc: 0.8542\n",
      "Epoch 15, Train Acc: 0.9393, Val Acc: 0.8625\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.90      0.95      0.92        19\n",
      "      banana       0.94      0.89      0.91        18\n",
      "       mixed       0.75      0.60      0.67         5\n",
      "      orange       0.89      0.94      0.92        18\n",
      "\n",
      "    accuracy                           0.90        60\n",
      "   macro avg       0.87      0.85      0.86        60\n",
      "weighted avg       0.90      0.90      0.90        60\n",
      "\n",
      "\n",
      "=== Training with AdamW, lr=0.001, lr_decay=0.7 ===\n",
      "Epoch 1, Train Acc: 0.3839, Val Acc: 0.5875\n",
      "Epoch 2, Train Acc: 0.6893, Val Acc: 0.7667\n",
      "Epoch 3, Train Acc: 0.7089, Val Acc: 0.7625\n",
      "Epoch 4, Train Acc: 0.8000, Val Acc: 0.8042\n",
      "Epoch 5, Train Acc: 0.8304, Val Acc: 0.8208\n",
      "Epoch 6, Train Acc: 0.8500, Val Acc: 0.8417\n",
      "Epoch 7, Train Acc: 0.8589, Val Acc: 0.8458\n",
      "Epoch 8, Train Acc: 0.8571, Val Acc: 0.8208\n",
      "Epoch 9, Train Acc: 0.8714, Val Acc: 0.8125\n",
      "Epoch 10, Train Acc: 0.8875, Val Acc: 0.8625\n",
      "Epoch 11, Train Acc: 0.9018, Val Acc: 0.8875\n",
      "Epoch 12, Train Acc: 0.9125, Val Acc: 0.8750\n",
      "Epoch 13, Train Acc: 0.9196, Val Acc: 0.8417\n",
      "Epoch 14, Train Acc: 0.9125, Val Acc: 0.8333\n",
      "Epoch 15, Train Acc: 0.9232, Val Acc: 0.8417\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.89      0.89      0.89        19\n",
      "      banana       0.90      0.50      0.64        18\n",
      "       mixed       0.30      0.60      0.40         5\n",
      "      orange       0.81      0.94      0.87        18\n",
      "\n",
      "    accuracy                           0.77        60\n",
      "   macro avg       0.73      0.73      0.70        60\n",
      "weighted avg       0.82      0.77      0.77        60\n",
      "\n",
      "\n",
      "=== Training with AdamW, lr=0.001, lr_decay=0.5 ===\n",
      "Epoch 1, Train Acc: 0.3982, Val Acc: 0.4458\n",
      "Epoch 2, Train Acc: 0.5821, Val Acc: 0.6625\n",
      "Epoch 3, Train Acc: 0.6571, Val Acc: 0.7208\n",
      "Epoch 4, Train Acc: 0.7768, Val Acc: 0.8000\n",
      "Epoch 5, Train Acc: 0.7821, Val Acc: 0.8042\n",
      "Epoch 6, Train Acc: 0.8071, Val Acc: 0.8083\n",
      "Epoch 7, Train Acc: 0.8393, Val Acc: 0.8250\n",
      "Epoch 8, Train Acc: 0.8536, Val Acc: 0.8292\n",
      "Epoch 9, Train Acc: 0.8750, Val Acc: 0.8458\n",
      "Epoch 10, Train Acc: 0.8786, Val Acc: 0.8458\n",
      "Epoch 11, Train Acc: 0.8804, Val Acc: 0.8250\n",
      "Epoch 12, Train Acc: 0.8857, Val Acc: 0.8500\n",
      "Epoch 13, Train Acc: 0.8911, Val Acc: 0.8500\n",
      "Epoch 14, Train Acc: 0.9232, Val Acc: 0.8708\n",
      "Epoch 15, Train Acc: 0.9179, Val Acc: 0.8583\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.89      0.89      0.89        19\n",
      "      banana       0.94      0.89      0.91        18\n",
      "       mixed       0.57      0.80      0.67         5\n",
      "      orange       0.94      0.89      0.91        18\n",
      "\n",
      "    accuracy                           0.88        60\n",
      "   macro avg       0.84      0.87      0.85        60\n",
      "weighted avg       0.90      0.88      0.89        60\n",
      "\n",
      "\n",
      "=== Training with AdamW, lr=0.0005, lr_decay=0.9 ===\n",
      "Epoch 1, Train Acc: 0.4571, Val Acc: 0.6208\n",
      "Epoch 2, Train Acc: 0.6536, Val Acc: 0.7792\n",
      "Epoch 3, Train Acc: 0.7500, Val Acc: 0.7583\n",
      "Epoch 4, Train Acc: 0.7804, Val Acc: 0.7833\n",
      "Epoch 5, Train Acc: 0.7964, Val Acc: 0.8042\n",
      "Epoch 6, Train Acc: 0.8393, Val Acc: 0.8458\n",
      "Epoch 7, Train Acc: 0.8232, Val Acc: 0.8292\n",
      "Epoch 8, Train Acc: 0.8464, Val Acc: 0.8583\n",
      "Epoch 9, Train Acc: 0.8768, Val Acc: 0.8458\n",
      "Epoch 10, Train Acc: 0.8804, Val Acc: 0.8125\n",
      "Epoch 11, Train Acc: 0.8696, Val Acc: 0.8583\n",
      "Epoch 12, Train Acc: 0.8857, Val Acc: 0.8500\n",
      "Epoch 13, Train Acc: 0.9161, Val Acc: 0.8625\n",
      "Epoch 14, Train Acc: 0.9161, Val Acc: 0.8667\n",
      "Epoch 15, Train Acc: 0.9089, Val Acc: 0.8750\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.89      0.89      0.89        19\n",
      "      banana       0.94      0.89      0.91        18\n",
      "       mixed       0.57      0.80      0.67         5\n",
      "      orange       0.94      0.89      0.91        18\n",
      "\n",
      "    accuracy                           0.88        60\n",
      "   macro avg       0.84      0.87      0.85        60\n",
      "weighted avg       0.90      0.88      0.89        60\n",
      "\n",
      "\n",
      "=== Training with AdamW, lr=0.0005, lr_decay=0.7 ===\n",
      "Epoch 1, Train Acc: 0.4179, Val Acc: 0.5833\n",
      "Epoch 2, Train Acc: 0.6143, Val Acc: 0.7250\n",
      "Epoch 3, Train Acc: 0.7286, Val Acc: 0.7792\n",
      "Epoch 4, Train Acc: 0.7911, Val Acc: 0.7708\n",
      "Epoch 5, Train Acc: 0.8214, Val Acc: 0.7917\n",
      "Epoch 6, Train Acc: 0.8232, Val Acc: 0.8333\n",
      "Epoch 7, Train Acc: 0.8679, Val Acc: 0.8375\n",
      "Epoch 8, Train Acc: 0.8661, Val Acc: 0.8333\n",
      "Epoch 9, Train Acc: 0.8732, Val Acc: 0.8542\n",
      "Epoch 10, Train Acc: 0.8554, Val Acc: 0.8250\n",
      "Epoch 11, Train Acc: 0.8875, Val Acc: 0.8333\n",
      "Epoch 12, Train Acc: 0.9036, Val Acc: 0.8458\n",
      "Epoch 13, Train Acc: 0.9232, Val Acc: 0.8417\n",
      "Epoch 14, Train Acc: 0.9250, Val Acc: 0.8542\n",
      "Epoch 15, Train Acc: 0.9268, Val Acc: 0.8500\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.85      0.89      0.87        19\n",
      "      banana       0.93      0.78      0.85        18\n",
      "       mixed       0.60      0.60      0.60         5\n",
      "      orange       0.85      0.94      0.89        18\n",
      "\n",
      "    accuracy                           0.85        60\n",
      "   macro avg       0.81      0.80      0.80        60\n",
      "weighted avg       0.85      0.85      0.85        60\n",
      "\n",
      "\n",
      "=== Training with AdamW, lr=0.0005, lr_decay=0.5 ===\n",
      "Epoch 1, Train Acc: 0.3625, Val Acc: 0.5250\n",
      "Epoch 2, Train Acc: 0.5536, Val Acc: 0.6292\n",
      "Epoch 3, Train Acc: 0.6768, Val Acc: 0.7292\n",
      "Epoch 4, Train Acc: 0.7464, Val Acc: 0.7750\n",
      "Epoch 5, Train Acc: 0.7982, Val Acc: 0.8167\n",
      "Epoch 6, Train Acc: 0.8321, Val Acc: 0.8208\n",
      "Epoch 7, Train Acc: 0.8321, Val Acc: 0.8583\n",
      "Epoch 8, Train Acc: 0.8554, Val Acc: 0.8333\n",
      "Epoch 9, Train Acc: 0.8696, Val Acc: 0.8417\n",
      "Epoch 10, Train Acc: 0.8804, Val Acc: 0.8000\n",
      "Epoch 11, Train Acc: 0.8857, Val Acc: 0.8458\n",
      "Epoch 12, Train Acc: 0.8946, Val Acc: 0.8583\n",
      "Epoch 13, Train Acc: 0.9214, Val Acc: 0.8500\n",
      "Epoch 14, Train Acc: 0.9036, Val Acc: 0.8542\n",
      "Epoch 15, Train Acc: 0.9036, Val Acc: 0.8542\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.94      0.89      0.92        19\n",
      "      banana       0.94      0.83      0.88        18\n",
      "       mixed       0.50      0.80      0.62         5\n",
      "      orange       0.89      0.89      0.89        18\n",
      "\n",
      "    accuracy                           0.87        60\n",
      "   macro avg       0.82      0.85      0.83        60\n",
      "weighted avg       0.89      0.87      0.87        60\n",
      "\n",
      "\n",
      "Saved training results to results/results_log_20250605_224203.csv\n",
      "Saved classification reports to results/classification_reports_20250605_224203.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class FruitCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FruitCNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 12 * 12, 256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def run_grid_search(train_path, test_path, optimizer_lr_dict, lrd_list, batch_size=16, epochs=10, seed=42):\n",
    "    set_seed(seed)\n",
    "\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize((100, 100)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize((100, 100)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "\n",
    "    train_data = ImageFolder(train_path, transform=transform_train)\n",
    "    test_data = ImageFolder(test_path, transform=transform_test)\n",
    "\n",
    "    train_size = int(0.7 * len(train_data))\n",
    "    val_size = len(train_data) - train_size\n",
    "    train_dataset, val_dataset = random_split(train_data, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Classes:\", train_data.classes)\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    csv_path = f\"results/results_log_{timestamp}.csv\"\n",
    "    report_path = f\"results/classification_reports_{timestamp}.txt\"\n",
    "\n",
    "    all_results = []\n",
    "    with open(report_path, \"w\") as report_file:\n",
    "        for opt_name, lr_list in optimizer_lr_dict.items():\n",
    "            for lr in lr_list:\n",
    "                for lrd in lrd_list:\n",
    "                    print(f\"\\n=== Training with {opt_name}, lr={lr}, lr_decay={lrd} ===\")\n",
    "                    model = FruitCNN().to(device)\n",
    "                    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "                    if opt_name == 'SGD':\n",
    "                        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "                    elif opt_name == 'Adam':\n",
    "                        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "                    elif opt_name == 'AdamW':\n",
    "                        optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unknown optimizer: {opt_name}\")\n",
    "\n",
    "                    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=lrd)\n",
    "\n",
    "                    train_acc, val_acc, train_loss, val_loss = [], [], [], []\n",
    "\n",
    "                    for epoch in range(epochs):\n",
    "                        model.train()\n",
    "                        correct, total, running_loss = 0, 0, 0.0\n",
    "                        for images, labels in train_loader:\n",
    "                            images, labels = images.to(device), labels.to(device)\n",
    "                            optimizer.zero_grad()\n",
    "                            outputs = model(images)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            running_loss += loss.item()\n",
    "                            _, predicted = torch.max(outputs, 1)\n",
    "                            correct += (predicted == labels).sum().item()\n",
    "                            total += labels.size(0)\n",
    "                        train_acc.append(correct / total)\n",
    "                        train_loss.append(running_loss)\n",
    "\n",
    "                        model.eval()\n",
    "                        val_correct, val_total, val_running_loss = 0, 0, 0.0\n",
    "                        with torch.no_grad():\n",
    "                            for val_images, val_labels in val_loader:\n",
    "                                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "                                val_outputs = model(val_images)\n",
    "                                val_loss_batch = criterion(val_outputs, val_labels)\n",
    "                                val_running_loss += val_loss_batch.item()\n",
    "                                _, val_preds = torch.max(val_outputs, 1)\n",
    "                                val_total += val_labels.size(0)\n",
    "                                val_correct += (val_preds == val_labels).sum().item()\n",
    "                        val_acc.append(val_correct / val_total)\n",
    "                        val_loss.append(val_running_loss)\n",
    "                        scheduler.step()\n",
    "\n",
    "                        print(f\"Epoch {epoch+1}, Train Acc: {train_acc[-1]:.4f}, Val Acc: {val_acc[-1]:.4f}\")\n",
    "\n",
    "                    model.eval()\n",
    "                    y_true, y_pred = [], []\n",
    "                    test_correct, test_total, test_running_loss = 0, 0, 0.0\n",
    "                    with torch.no_grad():\n",
    "                        for images, labels in test_loader:\n",
    "                            images, labels = images.to(device), labels.to(device)\n",
    "                            outputs = model(images)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                            test_running_loss += loss.item()\n",
    "                            _, preds = torch.max(outputs, 1)\n",
    "                            test_correct += (preds == labels).sum().item()\n",
    "                            test_total += labels.size(0)\n",
    "                            y_pred.extend(preds.cpu().numpy())\n",
    "                            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "                    test_acc = test_correct / test_total\n",
    "                    test_loss = test_running_loss\n",
    "\n",
    "                    report = classification_report(y_true, y_pred, target_names=train_data.classes)\n",
    "                    print(\"\\nClassification Report:\")\n",
    "                    print(report)\n",
    "\n",
    "                    report_file.write(\n",
    "                        f\"=== Optimizer: {opt_name}, LR: {lr}, Decay: {lrd} ===\\n{report}\\n\\n\"\n",
    "                    )\n",
    "\n",
    "                    all_results.append({\n",
    "                        'optimizer': opt_name,\n",
    "                        'lr': lr,\n",
    "                        'lr_decay': lrd,\n",
    "                        'final_train_acc': train_acc[-1],\n",
    "                        'final_val_acc': val_acc[-1],\n",
    "                        'final_train_loss': train_loss[-1],\n",
    "                        'final_val_loss': val_loss[-1],\n",
    "                        'test_acc': test_acc,\n",
    "                        'test_loss': test_loss\n",
    "                    })\n",
    "\n",
    "                    del model\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "    pd.DataFrame(all_results).to_csv(csv_path, index=False)\n",
    "    print(f\"\\nSaved training results to {csv_path}\")\n",
    "    print(f\"Saved classification reports to {report_path}\")\n",
    "\n",
    "# Configuration\n",
    "optimizer_lr_dict = {\n",
    "    'SGD': [0.01, 0.005],\n",
    "    'Adam': [0.001, 0.0005],\n",
    "    'AdamW': [0.001, 0.0005]\n",
    "}\n",
    "lrd_list = [0.9, 0.7, 0.5]\n",
    "\n",
    "# Run\n",
    "run_grid_search(\n",
    "    train_path=\"../train\",\n",
    "    test_path=\"../test\",\n",
    "    optimizer_lr_dict=optimizer_lr_dict,\n",
    "    lrd_list=lrd_list,\n",
    "    batch_size=32,\n",
    "    epochs=15,\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4f4645-5435-421d-9254-89260df7eedf",
   "metadata": {},
   "source": [
    "# Code Rationale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3723c7-a50e-486a-b772-fd148bfd78f4",
   "metadata": {},
   "source": [
    "| Component       | Purpose                                   |\n",
    "| --------------- | ----------------------------------------- |\n",
    "| 15 Epochs       | Enough for small dataset; avoids overfit  |\n",
    "| Resize(100x100) | Standardizes input size                   |\n",
    "| Flip + Rotate   | Augments data for better generalization   |\n",
    "| Normalize       | Speeds up and stabilizes learning         |\n",
    "| CNN Layers      | Extract low-to-high level visual features |\n",
    "| Dropout         | Regularization to reduce overfitting      |\n",
    "| Fully Connected | Decision making for classification        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c19098-5169-425f-9f2d-ef796f16bdf5",
   "metadata": {},
   "source": [
    "# Model Training & Evaluation Summary\n",
    "\n",
    "---\n",
    "\n",
    "## Model Training Observations\n",
    "\n",
    "- **Epochs**: 15  \n",
    "- **Initial Accuracy**: 45.83%  \n",
    "- **Final Training Accuracy**: 97.92%  \n",
    "- **Training Loss**: Decreased from 9.78 to approximately 0.45\n",
    "\n",
    "### Trend:\n",
    "- The model shows steady learning and convergence.\n",
    "- Accuracy and loss improvements indicate effective training and model fit.\n",
    "\n",
    "---\n",
    "\n",
    "## Test Set Performance\n",
    "\n",
    "| Class   | Precision | Recall | F1-score | Support |\n",
    "|---------|-----------|--------|----------|---------|\n",
    "| Apple   | 0.90      | 1.00   | 0.95     | 19      |\n",
    "| Banana  | 0.80      | 0.89   | 0.84     | 18      |\n",
    "| Mixed   | 0.00      | 0.00   | 0.00     | 5       |\n",
    "| Orange  | 0.89      | 0.94   | 0.92     | 18      |\n",
    "\n",
    "- Apple and Orange were classified very well.\n",
    "- Mixed class was completely misclassified — the model made no correct predictions.\n",
    "- Overall test accuracy was 87%.\n",
    "\n",
    "---\n",
    "\n",
    "## Warnings and Issues\n",
    "\n",
    "### PIL Warning:\n",
    "`Palette images with Transparency expressed in bytes should be converted to RGBA images`  \n",
    "Some images (e.g., `.png` or `.gif`) contain transparency and should be explicitly converted to RGBA to ensure proper processing.\n",
    "\n",
    "### UndefinedMetricWarning from sklearn:\n",
    "`Precision is ill-defined and being set to 0.0 in labels with no predicted samples.`  \n",
    "This occurs because the model never predicted the Mixed class, leading to undefined precision and recall values for that class.\n",
    "\n",
    "---\n",
    "\n",
    "## Overall Performance Summary\n",
    "\n",
    "- **Final Test Accuracy**: 87%\n",
    "- **Macro Average F1-score**: 0.68 (lower due to poor performance on Mixed)\n",
    "- **Weighted Average F1-score**: 0.83 (heavily influenced by Apple and Orange)\n",
    "\n",
    "---\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "1. Check class distribution in the training set to ensure the Mixed class is not underrepresented.\n",
    "2. Add more training examples for the Mixed class or apply data augmentation.\n",
    "3. Consider using class weighting in the loss function to compensate for class imbalance.\n",
    "4. Plot a confusion matrix to understand where the model is confusing Mixed with other classes.\n",
    "5. Ensure all images are correctly formatted and converted to RGB or RGBA where necessary.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876a3365-388d-4543-967c-be9ad712d0e8",
   "metadata": {},
   "source": [
    "# Why a 3-Layer CNN Architecture Was Chosen\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Progressive Feature Extraction\n",
    "\n",
    "- **Layer 1** learns basic features such as edges and textures.\n",
    "- **Layer 2** identifies more complex patterns like shapes and contours.\n",
    "- **Layer 3** extracts high-level, abstract features (e.g., outlines or combinations of shapes).\n",
    "- This hierarchy allows the model to understand images from simple to complex representations.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Suitable for Simple Visual Categories\n",
    "\n",
    "- The dataset involves fruits, which have **distinct colors, textures, and shapes**.\n",
    "- The resized image dimension is **100×100**, which is relatively low.\n",
    "- A deeper architecture would be overkill and may introduce unnecessary complexity.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Balanced Depth to Prevent Overfitting\n",
    "\n",
    "- **Too shallow (1–2 layers)**: May underfit and miss important patterns.\n",
    "- **Too deep (5+ layers)**: May overfit or require more data and compute.\n",
    "- **3 layers** is a balanced choice, offering enough capacity to learn without overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Efficient Feature Map Reduction\n",
    "\n",
    "- Input size: **100×100**\n",
    "- After 3 `MaxPool2d(2)` layers:\n",
    "  - Output size reduces as follows: `100 → 50 → 25 → 12`\n",
    "- The final feature maps are small and efficient to flatten for fully connected layers.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Proven Practical Effectiveness\n",
    "\n",
    "- 3-layer CNNs perform well on small to medium image datasets (e.g., MNIST, CIFAR-10).\n",
    "- Ideal for classification tasks with a **limited number of classes**.\n",
    "- Fast to train, interpretable, and good for prototyping or educational use.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Reason                            | Explanation                                                                 |\n",
    "|-----------------------------------|-----------------------------------------------------------------------------|\n",
    "| Hierarchical feature learning     | Captures visual patterns from edges to object shapes                        |\n",
    "| Appropriate model depth           | Deep enough to learn, but avoids unnecessary complexity                     |\n",
    "| Reduces overfitting risk          | Suitable depth for datasets with limited samples per class                  |\n",
    "| Efficient for 100×100 images      | Spatial dimensions reduce nicely through pooling                            |\n",
    "| Fast and effective                | Trains quickly, works well for fruit classification tasks                   |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04033c16-de97-42ef-9f75-9d3ed8bde891",
   "metadata": {},
   "source": [
    "# Recommended Number of Training Images and Rationale\n",
    "\n",
    "---\n",
    "\n",
    "## Recommended Number of Images per Class\n",
    "\n",
    "| Class     | Minimum Recommended | Ideal Target | Rationale |\n",
    "|-----------|---------------------|--------------|-----------|\n",
    "| Apple     | ≥ 100               | 200–500      | Performs well; more data helps improve generalization. |\n",
    "| Banana    | ≥ 100               | 200–500      | Decent performance; more examples improve robustness. |\n",
    "| Mixed     | ≥ 200               | 300–600+     | Currently underperforms; needs significantly more data. |\n",
    "| Orange    | ≥ 100               | 200–500      | Strong baseline; should maintain class balance. |\n",
    "\n",
    "---\n",
    "\n",
    "## Justifications and Rationale\n",
    "\n",
    "### 1. Preventing Class Imbalance\n",
    "\n",
    "- The `Mixed` class fails due to likely underrepresentation.\n",
    "- Adding more examples ensures balanced training and fairer model attention.\n",
    "- Balanced datasets reduce bias and improve classification accuracy across all classes.\n",
    "\n",
    "### 2. Enhancing Generalization\n",
    "\n",
    "- CNNs require visual variety (angle, lighting, background) to generalize.\n",
    "- Small datasets (<100/class) often cause overfitting — the model memorizes instead of learning patterns.\n",
    "- 300–500 images per class offer enough variability for a simple CNN to generalize well.\n",
    "\n",
    "### 3. Data vs Model Complexity\n",
    "\n",
    "- Your model is a **3-layer CNN**, which is relatively simple and data-efficient.\n",
    "- Such models typically perform well with 200–500 images per class, especially when combined with data augmentation.\n",
    "\n",
    "### 4. Empirical Evidence\n",
    "\n",
    "- Datasets like CIFAR-10 and Flowers102 use ~500+ images/class for good performance.\n",
    "- Deeper models like ResNet often need more data, but shallower models benefit greatly from just 300–600/class.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Recommendation\n",
    "\n",
    "| Class Type           | Minimum (per class) | Ideal (per class) | Priority     |\n",
    "|----------------------|----------------------|-------------------|--------------|\n",
    "| Well-performing      | 100–150              | 300–500           | Medium       |\n",
    "| Mid-performing       | 100–200              | 300–500           | Medium       |\n",
    "| Underperforming      | 200–300              | 400–600+          | High (focus) |\n",
    "\n",
    "> Aim for **~1500–2000 total images**, with **additional focus on the 'Mixed' class**.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Step\n",
    "\n",
    "Consider using data augmentation or collecting more labeled images. This will enhance the model’s ability to generalize and improve its accuracy across all classes.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bb0c1a-681b-43f2-8128-6906e0d26869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
